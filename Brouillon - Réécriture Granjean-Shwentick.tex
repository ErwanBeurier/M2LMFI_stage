\documentclass{article}

\include{packages}
\include{macros}

% Pour les itemize : 			\setlength{\itemsep}{-1mm}

% Variables pour le document

\author{BEURIER Erwan}
\title{M2 LFMI \\ BROUILLON }
\date{Année 2015-2016}

% Commandes de ce document

\newcommand{\sRAMif}[2]{\text{IF} (A=B) \{I( #1 )\} \text{ ELSE } \{I( #2 )\}}
\newcommand{\sRAMifc}[2]{\text{IF} (A_1=A_2) \{I( #1 )\} \text{ ELSE } \{I( #2 )\}}
\newcommand{\bbA}{\mathbb{A}}
\newcommand{\TRec}[1]{\text{TRec}\left(\mathbb{#1}\right)}
\newcommand{\TRecd}[1]{\text{TRec}_{2}\left(\mathbb{#1}\right)}
\newcommand{\dtimeram}{\text{DTIME}_{\text{RAM}}\left( \grozo{ n^k }\right)}

\begin{document}
	
	
	\paragraph{README}
	Ce fichier n'est qu'un brouillon de réécriture de l'article de Grandjean et Schwentick \emph{Machine-independent characterizations and complete problems for deterministic linear time} pour voir si ces notions peuvent s'étendre au temps $\grozo{n^k}$.
	
	
	\paragraph{Notations}
	
	Par abus de notation découlant de la théorie des ensembles, j'écrirai $n$ pour $\intint{0}{n-1}$ voire pour $\intint{1}{n}$ quand il n'y aura pas d'ambiguïté. De manière générale, si un terme ressemble à un entier naturel mais qu'il est mis à la place d'un ensemble, il faut le lire comme l'ensemble $\intint{0}{n-1}$.
	
	\pagebreak
	
	\paragraph{Preliminaries} (p.198)
	
		\subparagraph{RAM data structures} (p.198)
	

		\begin{definition}[RAM data structures]
			Soit $t$ un type, c'est-à-dire une signature fonctionnelle ne contenant que des symboles de constantes ou de fonctions unaires.
			
			Une RAM-structure $s$ de type $t$ est un uplet constitué de :
			\begin{itemize}
				\setlength{\itemsep}{-1mm}
				\item 	$n \in \naturels$ est la taille de la structure ;
				\item 	$C \in \naturels$ pour chaque symbole $C \in t$ ;
				\item 	$f : n \to \naturels$ pour chaque symbole $f \in t$.
			\end{itemize}
			
			On notera $s.n, s.C, s.f$ les composantes $n, C, f$ de $s$ (cette notation est à rapprocher de l'accès à un attribut ou à une fonction membre en programmation objet).
			
			On dira que $s$ est $c$-bornée pour $c\in\naturels$ lorsque $s.C, s.f(i) < c s.n$ pour tous $C, f \in t$ et $i \in n$.
		\end{definition}
	
	
		\begin{definition}[Fonction de RAM]
			Soient $t_1, t_2$ des types. 
			
			Une $(t_1, t_2)$-fonction de RAM $\Gamma$ est une fonction telle qu'il existe $c_1, c_2 \in \naturels$, tels que $\Gamma$ envoie les structures $c_1$-bornées de type $t_1$ sur des structures $c_2$-bornées de type $t_2$.
			
			% On rappelle que "c-borné" ne concerne que la structure par rapport à sa propre taille ; ici on ne compare pas la taille de l'entrée et de la sortie
			
			On dit que $\Gamma$ est polynomiale lorsque $\Gamma(s).n = \grozo{(s.n)^k}$.
			
			% Là, si.
		\end{definition}
	
	
	
		\subparagraph{Machine RAM} (p.200)
	
		
		La machine RAM reste la même (heureusement). On va utiliser la $\{+\}$-RAM ou des versions un brin plus puissantes comme la $\{+ , -, \times, \div k \}$-RAM pour un $k\in \naturels$ fixé.
		
		\begin{definition}[Temps polynomial]
			On définit $\dtimeram$ comme étant l'ensemble des fonctions calculables sur $\{+\}$-RAM en temps $\grozo{n^k}$, telles que le nombre de registres utilisés, la longueur des nombres manipulés (y compris les adresses de registres) soient bornés par $\grozo{n^k}$.
		\end{definition}
		
		
		
		\subparagraph{Réductions affines} (p.202)


		On laisse inchangées les notions de \emph{transformations affines} (définition 2.3), de \emph{réductions affines} (définition 2.5),de projections affines (définition 2.7). Les théorèmes et lemmes suivants ou intermédiaires sont aussi inchangés. Ils permettront de définir des réductions qui \emph{restent} dans $\dtimeram$ pour un $k$ fixé.
		
		
		
	\paragraph{Le framework algébrique} (p.208)


		\subparagraph{LSRS} (p.208)
		
		
		Le LSRS en tant que tel n'a pas l'air collé à la définition du temps linéaire. On garde la définition pour le moment. 
		
		On doit refaire la définition 3.3.
		
		Pour $t$ un type, on note $F_t$ l'ensemble de symboles de fonctions suivants : $\{1(-), n(-), id(-)\} \cup  \{ f_C | C \in t\} \cup \{ f | f \in t\}$.
		
		\begin{remark}
			Soient $t$ un type et $S$ un LSRS pour $f_1, \dots, f_h$ sur $F_{t}$. 
			L'entrée d'un LSRS peut être vue comme étant une RAM-structure $s$ de type $t$, qu'il \emph{lit} en interprétant les symboles de $F_t$ de la façon suivante : 
			
			\begin{itemize}
				\item 	$\forall f \in t_1$ :   $f(i) = 
				\left\lbrace \begin{array}{ll}
				s.f(i) & \text{si } i< s.n \\
				0 & \text{sinon}
				\end{array}\right.$
				
				\item 	$\forall C \in t_1$ :   $f_C(i) = s.C$
				\item 	$1(i) = 1, n(i) = s.n, id(i) = i$
			\end{itemize}
			
			La sortie du LSRS peut aussi être vue comme une nouvelle structure $s' = S(s)$ de type $\{f_1, \dots, f_h\}$.
		\end{remark}
		
		
		Ici, on a plusieurs possibilités pour adapter le concept de \emph{linéairement représenté} (définition 3.3) à $n^k$.
		
		\begin{definition}[RAM $n^k$-représentée par LSRS - Proposition 1]
			Soient $t_1, t_2$ des types. Soit $\Gamma$ une $(t_1, t_2)$-fonction de RAM. 
			
			Soit $S$ un LSRS pour $f_1, \dots, f_h$ sur $F_{t_1}$. 
			
			On dit que $\Gamma$ est $n^k$-représentée par $S$ lorsqu'il existe un entier $c$ et une projection affine $P$ tels que, pour chaque structure $s$ $c$-bornée, $S$ définit des fonctions $f_1, \dots, f_h : c (s.n)^k \to c (s.n)^k$ telles que $\Gamma(s) = P((s.n)^k, S(s))$ ($S(s)$ est la structure définie par le LSRS).
			
			\emph{La modification réside dans le domaine de définition des fonctions et la taille de la sortie dans la projection.}
		\end{definition}
			
		
		\begin{probs} \textcolor{white}{T} % Obligé pour sauter une ligne.
			\begin{itemize}
				\setlength{\itemsep}{-1mm}
				\item 	Est-ce qu'on capture tout $\dtimeram$ ? 
				\item 	Est-ce que $P((s.n)^k, S(s))$ capture toutes les structures de taille $\grozo{n^k}$ ?
			\end{itemize}
		\end{probs}
			
	
		Si $\Gamma$ est $n^k$-représentée par un LSRS alors on dit que $\Gamma$ est définissable par LSRS. 
		
		
		% Eventuellement d'autres possibilités
		
		La définition 3.4 (définition par cas) et les lemmes 3.5 (la définition par cas ne change pas la puissance des LSRS) et 3.6 (composition de fonctions définissables par LSRS reste définissable par LSRS) restent les mêmes.
		
		
		\subparagraph{LRS} (p.211)
		
		La définition d'un terme récursif (non numérotée) et d'un LRS (définition 3.7) restent les mêmes. Le lemme 3.8 d'existence d'une solution unique au LRS aussi. 
		
		On doit adapter la définition de $n^k$-représentée par LRS : 
		
		\begin{definition}[RAM $n^k$-représentée par LRS - Proposition 1]
			Soit $\Gamma$ une fonction de RAM. 
			
			Soit $E$ un LSRS $g(x) = \sigma(x)$. 
			
			On dit que $\Gamma$ est $n^k$-représentée par $E$ lorsqu'il existe un entier $c$ et une projection affine $P$ tels que, pour chaque structure $s$ $c$-bornée, $E$ définit une fonction $g : c (s.n)^k \to c (s.n)^k$ telle que $\Gamma(s) = P((s.n)^k, E(s)$ ($E(s)$ est la structure définie par le LRS, elle est de type $\{g\}$).
			
			\emph{La modification réside dans le domaine de définition de $g$.}
		\end{definition}
		
		Et là, c'est la foire.
		
		On doit vérifier si le théorème principal de l'article tient encore au temps polynomial.
		
		
		
		\begin{conj}[Adaptation du lemme 3.10 (p.212)]
			Toute fonction de RAM $n^k$-représentée par LSRS est aussi $n^k$-représentable par LRS.
		\end{conj}
		
		\begin{proof}
			Ici commence la relecture de la preuve.
			
			
		\end{proof}
\end{document}

















