\documentclass{report}

\include{packages}
\include{macros}

% Pour les itemize : 			\setlength{\itemsep}{-1mm}

% Variables pour le document

\author{BEURIER Erwan}
\title{M2 LFMI \\ MEMOIRE DE STAGE \\ Unification des modèles de calculs caractérisant le temps polynomial}
\date{Année 2015-2016}

% Commandes de ce document

% Commandes personnelles pour le premier chapitre

\newcommand{\sRAMif}[2]{\text{IF} (A=B) \{I( #1 )\} \text{ ELSE } \{I( #2 )\}}
\newcommand{\sRAMifc}[2]{\text{IF} (A_1=A_2) \{I( #1 )\} \text{ ELSE } \{I( #2 )\}}
\newcommand{\bbA}{\mathbb{A}}
\newcommand{\TRec}[1]{\text{TRec}\left(\mathbb{#1}\right)}
\newcommand{\TRecd}[1]{\text{TRec}_{2}\left(\mathbb{#1}\right)}
\newcommand{\MEM}[1]{\text{MEM}\left( #1 \right)}
\newcommand{\aramsw}[3]{\text{(switch)}	s_{#1} #2 #3} % Commande switch
\newcommand{\aramconsz}[4]{\text{(const)}	s_{#1} #2 #3 s_{#4}} % Constructeurs 0-aires
\newcommand{\aramconst}[5]{\text{(const)}	s_{#1} #2 #3 #4 s_{#5}} % Constructeurs (>0)-aires
\newcommand{\aramdest}[5]{\text{(#1-dest)} 	s_{#2} #3 #4 s_{#5}} % Commande destructeur.
\newcommand{\aramfn}[3]{\text{(fn)} 		s_{#1} #2 s_{#3}}

\begin{document}
	
	\maketitle
	
	\pagebreak
	
	\section*{Précision et notations}
	\label{sec:Notations}
	
	Je n'aime pas que les liens hypertextes soient trop visibles, mais je n'ai pas encore cherché comment on pouvait les rendre visibles ET discrets, donc pour l'instant, ils sont simplement invisibles. Ne pas hésiter à passer la souris sur des mots comme \emph{ici}, \emph{plus bas}, etc ; ils seront très probablement munis d'un lien hypertexte. Les références à des sections, définitions, théorèmes, etc. sont aussi cliquables.
	
	Par abus de notation découlant de la théorie des ensembles, j'écrirai $n$ pour $\intint{0}{n-1}$ voire pour $\intint{1}{n}$ quand il n'y aura pas d'ambiguïté. De manière générale, si un terme $n$ ressemble à un entier naturel mais qu'il est mis à la place d'un ensemble (typiquement, dans le domaine de départ ou d'arrivée d'une fonction), il faut le lire comme l'ensemble $\intint{0}{n-1}$.
	
	\section*{TODO List}
	
	\nepasoublier{NE PAS OULIER}
	
	\begin{itemize}
		\item 	Sources pour Cobham et l'équivalence de $P$ (pour Turing) et $P$ (pour RAM).
	\end{itemize}
	
	\pagebreak
	
	
	
	\tableofcontents
	
	
	\pagebreak
	
	
	\section*{Introduction}
	
	Il existe de nombreuses caractérisations de $FP$ (notée dans la suite $P$ par abus de langage). Parmi les plus fameuses, on peut citer celle de Bellantoni et Cook \cite{BellantoniCook1992} ou celle de Cobham. Ce sont des caractérisations sur la récurrence, qui permettent de traduire le temps de calcul sur un modèle comme la machine de Turing en contraintes sur les définitions des fonctions, notamment en contrôlant leur récurrence. 
	
	Cependant, ces caractérisations ont plusieurs défauts que l'on va essayer de corriger dans ce mémoire :
	
	\begin{itemize}
		\item 
				Ces caractérisations ne \emph{communiquent} pas, dans le sens où elles passent en général par leur modèle de calcul (machine de Turing ou machine RAM) ; parfois, leurs modèles de calculs sont même spécifiques à la caractérisation. Les buts du chapitre \ref{chap:unif_P} sont premièrement, de trouver des passerelles entre diverses caractérisations sans passer par leur machine respective, et deuxièmement, d'expliciter une simulation entre deux de ces machines ;
				
		\item 
				Elles caractérisent $P$ globalement, mais ne permettent pas de caractériser des classes plus précises (à savoir, le temps polynomial à polynôme fixé). Le chapitre \ref{chap:rLSRS} explore une caractérisation de telles classes en s'inspirant d'un travail effectué sur le temps linéaire \cite{GrandjeanSchwentick2002}.
	\end{itemize}
	
	
	\pagebreak
	
	\chapter{Unification de deux caractérisations de $P$}
	\label{chap:unif_P}
	
	\section{Des caractérisations de $P$}
		\label{sec:caracterisations_P}
	
		Dans cette section, on présente quelques caractérisations connues de $P$. Le but de ce premier chapitre va être de lier ces caractérisations de manière plus directe. 
	
		\subsection{Notions générales}
			\label{subsec:notions_generales}
		
			Commençons par quelques notions générales.
	
			\begin{definition}[Algèbre \cite{Leivant1995}]
				\label{def:algebre}
				Soit $\sigma = \left\lbrace C_1, \dots, C_k \right\rbrace$ un ensemble de symboles de fonctions. Dans la suite, $k$ représentera le nombre de constructeurs dans la signature.
				
				La $\sigma$-algèbre $\bbA$ est l'ensemble des termes clos constitués uniquement par les symboles de fonctions de $\sigma$. Dans ce cas, ces fonctions sont nommées \emph{constructeurs}. 
				
				On note $r_i$ l'arité du constructeur $C_i$. On suppose que $\minlist{r_i}{i\in\intint{1}{k}} = 0$ (sinon $\bbA$ est vide) et $\maxlist{r_i}{i\in\intint{1}{k}} = r > 0$ (sinon $\bbA$ est finie).
				
				Si $r = 1$ alors $\mathbb{A}$ est une \emph{algèbre de mots}, sinon c'est une \emph{algèbre arborescente}.
				
				Soit un terme $\tau \in \bbA$. On appelle \emph{constructeur extérieur} le dernier constructeur de $\tau$. On peut le définir par induction comme suit :
				
				\begin{itemize}[itemsep=-1mm]
					\item 	Si $\tau = C_i$ où $r_i = 0$ alors $C_i$ est le constructeur extérieur de $\tau$.
					\item 	Si $\tau = C_i(\tau_1, \dots, \tau_{r_i})$ alors $C_{i}$ est le constructeur extérieur de $\tau$.
				\end{itemize}
			\end{definition}
			
			
			\begin{example} On distingue deux algèbres particulières :
				\begin{itemize}[itemsep=-1mm]
					\item 	la $\left\lbrace 0, s \right\rbrace$-algèbre des entiers unaires $\naturels$ ;
					\item 	la $\left\lbrace \varepsilon, 0(-), 1(-)\right\rbrace$-algèbre des mots binaires $\mathbb{W}$.
				\end{itemize}
			\end{example}
	
			On définit alors la récurrence sur des algèbres de la façon suivante :
			
			\begin{definition}[Définition par récurrence sur une algèbre]
				La fonction $f : \bbA \to \bbA$ est définie par récurrence à partir des fonctions $\left(g_c\right)_{c \in \sigma}$ lorsque pour tout constructeur $c$ :
				
				\[
					f\left(c(x), \bar{y}\right) = g_c\left( x, \bar{y}, f(x, \bar{y}) \right)
				\]
			\end{definition}


		
		\subsection{Approche de Cobham}
		\label{sec:Cobham}
		
			On se place dans le cas des mots : $\sigma = \{ C_1, \dots, C_k \}$ où $\minlist{C_i}{i \in k} = 0$ et $\maxlist{C_i}{i \in k} = 1$.
			
			
			\begin{definition}
				\label{def:Cob}
				On note $\text{Cob}$ le plus petit ensemble de fonctions contenant les constructeurs, les projections, le smash $x \sharp y = 2^{\left| x \right| \times \left| y\right|}$, et close par composition et récurrence bornée sur les notations.
				
				\hspace{0.05\linewidth}\parbox{0.9\linewidth}{
					\small
					\emph{Une fonction $f \in \text{Cob}$ est définie par récurrence bornée sur les notations à partir de $(g_c)_{c \in \sigma}, h \in \text{Cob}$ lorsque :}
					
					\begin{itemize}[itemsep=-1mm]
						\item 	$\forall c \in \sigma, \:\:\: f\left( c(x), \bar{y} \right) = g_c\left( x, \bar{y} \right)$
						\item 	$\forall x, \bar{y}, \:\:\: \left| f \left( x, \bar{y} \right) \right| \leq \left| h \left( x, \bar{y} \right) \right|$
					\end{itemize}
				}
				
			\end{definition}
			
			
			\begin{theorem}[Cobham]
				\label{thm:Cob_equals_P}
				$\text{Cob} = P$
			\end{theorem}
		
			L'inclusion $P \subset \text{Cob}$  consiste à réécrire les fonctions de base de $P$ avec les fonctions de $\text{Cob}$ ; l'inclusion inverse vient du fait que la borne est toujours polynomiale.
			
			Conséquence : il existe une borne explicite pour chaque fonction de $P$. 
		
		
		
		\subsection{Approche de Bellantoni et Cook}
			\label{subsec:bellantoni_cook}
		
			L'idée de Bellantoni et Cook \cite{BellantoniCook1992} est qu'on peut séparer les arguments d'une fonction en deux types. Le premier type, les arguments \emph{normaux}, sont des arguments qu'on suppose bornés de manière implicite. Typiquement, un argument de récurrence est un argument normal : il ne faut pas, dans la définition par récurrence, que cet argument grossisse trop vite, car il risquerait d'entraîner un nombre croissant d'itérations. 
			
			\begin{example}
				
				Considérons les définitions par récurrence suivantes (dans l'algèbre $\naturels$) :
				
				\begin{enumerate}
					\item	\label{itm:addition}
							Addition : $+(0 , y) = y$ et $+(s(x), y) = s\left( +(x, y)\right)$ ; 
							
					\item	\label{itm:multiplication}
							Multiplication : $\times \left( 0, y \right) = 0$ et $\times \left( s(x), y \right) = +\left( x, \times\left( x, y \right) \right)$ ; 
							
					\item	\label{itm:exponentielle}
							Exponentielle : $\exp(0) = 1$ et $\exp(s(x)) = \exp(x) + \exp(x)$.
				\end{enumerate}
				
				Dans ces trois cas, le premier argument est appelé \emph{argument de récurrence}, puisque c'est celui-ci qui, en quelques sortes, compte le nombre d'étapes de récurrence. Dans l'addition, l'argument $s(x)$ devient $x$ dans l'appel récursif ; idem pour la multiplication. Dans ces deux cas, l'argument de récurrence décroît à chaque appel récursif. 
				
				Dans le cas de l'exponentielle par contre, l'argument $s(x)$ devient $\exp(x)$ en tant qu'argument de récurrence de $+(-,-)$. L'idée de Bellantoni et Cook est d'empêcher cette situation d'apparaitre.
				
			\end{example}
			
			
			
			
			On se place dans une algèbre de mots (tous les constructeurs de l'algèbre sont d'arité au plus $1$).
			
			\begin{definition}[Fonctions récursives à arguments normaux \cite{BellantoniCook1992}]
				\label{def:BC}
				On note $\text{BC}$ le plus petit ensemble de fonctions contenant :
				
				\begin{itemize}[itemsep=-1mm]
					\item 	les constructeurs \emph{safe} : $C_i\left(; x\right)$
					\item 	les projections : $p_i^{k,h} \left( x_1, \dots, x_{k}; x_{k+1}, \dots, x_{k+h}\right) = x_i$
					\item 	le destructeur \emph{safe} : $\text{dest} \left( ; C_i\left(; x\right) \right) = 
								\left\lbrace \begin{array}{ll}
									C_i	& \text{si $r_i = 0$} \\
									x	& \text{sinon}
								\end{array} \right.$
					\item 	la conditionnelle \emph{safe} : $\text{if}\left( ; x, y, z \right) = 
						\left\lbrace \begin{array}{ll}
							y	& \text{si $x \mod{2} = 0$} \\
							z	& \text{sinon}
						\end{array} \right.$
				\end{itemize}
				
				et étant close par schéma de récursion \emph{safe}
				
				
				\hspace{0.1\linewidth}\parbox{0.9\linewidth}{
					\small
					\emph{La fonction $f$ est définie par récurrence \emph{safe} à partir de $\left(g_c\right)_{c \in \sigma} \in \text{BC}$ lorsque pour tout constructeur $c$ :}
					
					\[
						f\left(c(;x), \bar{y} ; \bar{z}\right) = g_c\left( x, \bar{y} ; \bar{z}, f(x, \bar{y}; \bar{z}) \right)
					\]
				}
	
	
				et composition \emph{safe}.
				
				\hspace{0.1\linewidth}\parbox{0.9\linewidth}{
					\small
					\emph{La fonction $f$ est définie par composition \emph{safe} à partir de $h, g_0, g_1 \in \text{BC}$ lorsque :}
					
					\[
						f\left( \bar{x} ; \bar{y}\right) = h\left( \bar{x}, g_0( \bar{x}; ) ; \bar{y}, g_1( \bar{x}; \bar{y} ) \right)
					\]
				}
				
			\end{definition}
			
			
			\begin{theorem}[Bellantoni et Cook \cite{BellantoniCook1992}]
				\label{thm:BC_equals_P}
				$\text{BC} = P$
			\end{theorem}
	
			On démontre en fait $P \subseteq \text{BC} \subseteq \text{Cob}$. La première inclusion se fait en séparant les arguments \emph{safe} et \emph{normaux} dans les définitions des fonctions. La deuxième inclusion se trouve en explicitant par induction une borne sur les fonctions de $\text{BC}$. 
		
		
		
		\subsection{Approche de Leivant}
		\label{subsec:Leivant}
	
			Une autre façon de voir les choses est l'approche de Leivant, qui se rapproche de celle de Bellantoni et Cook.
			
			Considérons de nouveau une algèbre quelconque $\bbA$ de signature $\sigma = \left\lbrace C_1, \dots, C_k \right\rbrace$, composée de $k$ symboles de fonctions d'arité respective $r_i$. Dans la suite, $k$ représentera le nombre de constructeurs dans la signature.
			
			\espace
				
			On note $(\bbA_i)_{i\in \omega}$ l'ensemble des copies de l'algèbre $\bbA$, qui correspondent à des niveaux d'abstraction de $\bbA$, c'est-à-dire, une manière de hiérarchiser les arguments d'une fonction. On notera $\mathcal{A}$ n'importe quel produit cartésien fini de copies de $\bbA$. Pour $x\in \bbA_i$, on note $\text{tier}(x) = i$. De même, pour $f : \mathcal{A} \to \bbA_i$, on note $\text{tier}(f) = i$. Chaque tier a de plus ses propres constructeurs. Le constructeur $C_j$ du niveau $i$ sera noté $C_j^i$. 
			
			\begin{definition} 
				\label{def:TRecA}
				On note $\TRec{A}$ le plus petit ensemble de fonctions récursives primitives sur $\bbA$ contenant les constructeurs, les projections et étant clos par composition ramifiée et récurrence ramifiée.
				
				\espace
				
				\hspace{0.1\linewidth}\parbox{0.9\linewidth}{
					\small
					Une fonction est définie par récurrence ramifiée lorsque :
					
					\begin{itemize}
						\item 	$\forall i \:\:\:\:
						f(c_i^j(a_1, \dots, a_{r_i}), \bar{x}) 
						= g_{c_i}\left( f(a_1, \bar{x}), \dots, f(a_{r_i}, \bar{x}), \bar{a}, \bar{x} \right)
						$
					\end{itemize}
				}
				
				\espace
				
				On note $\TRecd{A}$ le sous-ensemble de $\TRec{A}$ dont chaque fonction est constructible en n'utilisant que deux tiers $\bbA_0, \bbA_1$.
			\end{definition}
			
			Un résultat intéressant est que si une fonction $f \in \TRec{\bbA}$ a des arguments de tiers inférieur à son tier d'arrivée, alors $f$ \emph{ignore} ces arguments.
			
			\espace 
			
			En plus de ça, on va définir une notion de degré d'imbrication, qui sert en somme de compteur de tours de boucles. 
			
			
			\begin{definition}[Degré d'imbrication de récurrence\footnotemark]
				\label{def:degre_recurrence}
				
				Soit $f \in \TRec{A}$. 
				
					\footnotetext{Pour être rigoureux, le degré de récurrence ne s'applique pas à une fonction, mais à une \emph{définition de fonction}.}
				
				Le degré d'imbrication de récurrence de $f$, noté $\delta(f)$, est un entier défini par induction sur la définition de $f$ :
				
				\begin{itemize}[itemsep=-1mm]
					\item 	Si $f$ est un constructeur ou une projection, alors $\delta(f) = 0$.
					\item 	Si $f$ est définie par composition, sans perte de généralité, $f(\bar{x}) = g\left( \bar{x}, h\left( \bar{x}\right)\right)$, alors :
					
							\begin{itemize}[itemsep=-1mm]
								\item 	Si $\text{tier}(h) < \text{tier}(g)$ alors $\delta(f) = \delta(g)$ ;
								\item 	Si $\text{tier}(h) = \text{tier}(g)$ alors $\delta(f) = \max\left(\delta(g), \delta(h)\right)$ ;
								\item 	Si $\text{tier}(h) > \text{tier}(g)$ alors $\delta(f) = \max\left(1, \delta(h)\right) \times \delta(g)$ ;
							\end{itemize}
							
					\item 	Si $f$ est définie par récurrence ramifiée $f(c_i^j(a_1, \dots, a_{r_i}), \bar{x}) = g_{c_i}\left( f(a_1, \bar{x}), \dots, f(a_{r_i}, \bar{x}), \bar{a}, \bar{x} \right)$, telles que $\left( g_{\alpha_j}\right)_{j\in p}$ aient des arguments critiques et $\left( g_{\beta_j}\right)_{j\in q}$ n'en aient pas, alors $\delta(f) = \max\left( 1 + \delta\left( g_{\alpha_1} \right), \dots,  1 + \delta\left( g_{\alpha_p} \right), \delta\left( g_{\beta_1} \right), \dots,  \delta\left( g_{\beta_q} \right)\right)$. 
				\end{itemize}
			\end{definition}
			
			
			Leivant définit aussi une RAM personnalisée pour la construction de termes, voir la définition \ref{def:A_RAM}. Cette RAM, notée $\bbA$-RAM dans ce mémoire, coïncide avec les autres modèles de calcul sur la classe $P$, mais son manque de test d'égalité et sa mémoire limitée la rendent moins puissante qu'une \hyperref[def:sigma_RAM]{RAM au sens de Grandjean-Schwentick} \cite{GrandjeanSchwentick2002} sur des classes plus fines (voir la section \ref{subsubsec:sim_A_RAM_sigma_RAM} pour la comparaison).
			
			\espace
			
			Les principaux résultats de Leivant ne concernent que les algèbres de mots. Voici les résultats de cet article \cite{Leivant1995} qui nous intéressent dans le cadre de ce mémoire :
			
			\begin{theorem}
				\label{thm:TRecA_equals_P_poly_fixe}
				Soit $\bbA$ une algèbre de mots. Soit $f : \mathcal{A} \to \bbA $.
				
				Les propositions suivantes sont équivalentes :
	
				\begin{itemize}[itemsep=-1mm]
					\item 	$f$ est calculable en temps $\grozo{n^k}$ sur une $\bbA$-RAM;
					\item 	$f$ est définissable par récurrence ramifiée sur deux tiers $\bbA_0, \bbA_1$ et $\delta(f) \leq k$ ;
					\item 	$f$ est définissable par récurrence ramifiée et $\delta(f) \leq k$.
				\end{itemize}
			\end{theorem}
			
			On a une caractérisation très fine des classes de complexité à polynôme fixé sur la $\bbA$-RAM.
			
			Le deuxième résultat important de \cite{Leivant1995} est :
			
			\begin{theorem}
				\label{thm:TRecA_equals_P}
				$\TRec{A} = \TRecd{A} = P$
			\end{theorem}
			
			La récurrence ramifiée engendre $P$ et deux niveaux de ramification suffisent.
		
			Le théorème \ref{thm:TRecA_equals_P_poly_fixe} a été prouvé pour une $\bbA$-RAM ; l'un des objets de ce stage a été d'obtenir un résultat analogue pour la RAM au sens de Grandjean-Schwentick, voir les chapitres \ref{chap:LSRS} et \ref{chap:rLSRS}.
			
		
	
		\subsection{Correspondance entre Bellantoni et Cook et Leivant}
		\label{subsec:corres_BC_Leivant}
	
			Le point de départ de Leivant est différent de celui de Bellantoni et Cook, mais le résultat est similaire. En fait, il y a une correspondance naturelle entre le résultat de Bellantoni et Cook et celui de Leivant.
			
			\begin{lemma}
				\label{lem:BC_and_Leivant}
				Soit $f \in P$, $f$ fonction sur $\mathbb{W}$ (mots binaires).
				
				Un argument $x$ de $f$ est \emph{normal} dans $\text{BC}$ si et seulement si $\text{tier}(x) > \text{tier}(f)$ dans $\TRec{W}$.
				
				Un argument $x$ de $f$ est \emph{safe} dans $\text{BC}$ si et seulement si $\text{tier}(x) \leq \text{tier}(f)$ dans $\TRec{W}$.
			\end{lemma}
			
			\begin{proof}
				\textcolor{white}{T} %exte blanc inutile pour passer à la ligne.
				
				\textbf{Passage de $\text{BC}$ à $\TRec{W}$}
				
				Un constructeur \emph{safe} $C_i(; x)$ se traduit naturellement en un constructeur \emph{plat} (le tier de départ est égal au tier d'arrivée). Les projections se traduisent naturellement aussi en suivant cette règle.
				
				Le destructeur \emph{safe} $\text{dest} \left( ; C\left(; x\right) \right)$ est définissable par récurrence plate (sans appel récursif) dans $\TRec{W}$ : 
				
				\[
					\text{dest} \left( C_i\left( x\right) \right) = 
					\left\lbrace \begin{array}{ll}
					C_i	& \text{si $r_i = 0$} \\
					x	& \text{sinon}
					\end{array} \right.
				\]
				
				Une ramification triviale donne $\text{dest} : \bb{W}_i \to \bb{W}_i$.
				
				De même, la conditionnelle \emph{safe} $\text{if} \left( ; x, y, z\right)$ est définissable par récurrence plate dans $\TRec{W}$ : 
				
				\[
					\begin{array}{l}
					\text{case}(\varepsilon, y, z) = y \\
					\text{case}(0(x), y, z) = y \\
					\text{case}(1(x), y, z) = z
					\end{array}
				\]
				
				Une ramification triviale donne $\text{case} : \mathbb{W}_i^3 \to \mathbb{W}_i$.
				
				Soit $f$ définie par composition \emph{safe} $f\left( \bar{x} ; \bar{y}\right) = h\left( \bar{x}, g_n( \bar{x}; ) ; \bar{y}, g_s( \bar{x}; \bar{y} ) \right)$.
				
				Par hypothèse d'induction, 
				
				\[
					\begin{array}{ll}
					g_n : \overline{\bb{W}_{k_n}} \to \bb{W}_{i_n} & \text{avec $k_n > i_n$}\\
					g_s : \overline{\bb{W}_{k_s}} \times \overline{\bb{W}_{j_s}} \to \bb{W}_{j_s} & \text{avec $k_s > j_s$} \\
					h : \overline{\bb{W}_{k_h}} \times \overline{\bb{W}_{i_h}} \times \overline{\bb{W}_{j_h}} \times \overline{\bb{W}_{j_h}} \to \bb{W}_{j_h} & \text{avec $k_h, i_h > j_h$}
					\end{array}
				\]
				
				Remarquons d'abord que, si une fonction $f_{i,j} : \bb{W}_i \to \bb{W}_j$ est définissable par récurrence ramifiée en utilisant des tiers dans $\intint{0}{k}$, alors il existe $f_{i+h, j+h} : \bb{W}_{i+h} \to \bb{W}_{j+h}$ définissable par récurrence ramifiée utilisant des tiers dans $\intint{h}{k+h}$ pour tout $h \in \omega$ (la démonstration se fait par une induction automatique sur la construction de $f_{i,j}$). De plus, il existe $f_{i+h,j} : \bb{W}_{i+h} \to \bb{W}_j$ pour tout $h \in \omega$ (il suffit pour cela de composer avec une fonction dite de coercion $\kappa_{i,j} : \bb{W}_i \to \bb{W}_j, i>j$, qui convertit un élément d'un tier en un tier inférieur).
				
				De ce fait, on peut choisir $g_n, g_s$ et $h$ telles que les tiers correspondent, à savoir : $i_n = i_h = i$, $j_h = j_s = j$ et $k_h = k_n = k_s = k$. Le résultat découle naturellement : $f : \overline{\bb{W}_{k}} \times \overline{\bb{W}_{j}} \to \bb{W}_{j}$.
				
				Pour la définition par récurrence, le raisonnement est similaire. 
				
				\espace
				
				\textbf{Passage de $\TRec{W}$ à $\text{BC}$}
				
				\begin{lemma}[Leivant \cite{Leivant1995}]
					\label{lem:arg_redondant}
					Soit $f : \bb{A}_i \times \mathcal{A} \to \bb{A}_j$. Si $i < j$ alors $\forall x, f(x, \bar{x}) = f(C, \bar{x})$ où $C$ est un constructeur d'arité $0$ de $\bb{A}$.
				\end{lemma}
				
				Si l'argument d'une fonction est d'un tier inférieur à celui de la fonction, alors cet argument est inutile à la fonction. En un sens, il n'est pas assez abstrait. Un tel argument est dit \emph{redondant}.
				
				Dans la suite, on suppose que les fonctions utilisées n'ont pas d'arguments redondants. De plus, pour simplifier, on va supposer qu'on n'utilise que deux tiers $\bbA_0, \bbA_1$ (ce qui est permis d'après le théorème \ref{thm:TRecA_equals_P}).
				
				Reprenons la démonstration du passage de Leivant à Bellantoni et Cook. Pour des raisons de lisibilité, on écrira $\underset{i}{x}$ pour dire que $x$ est dans le tier $i$.
				
				Le cas des constructeurs et des projections est trivial.
				
				Si $f(\underset{1}{\bar{x}}, \underset{0}{\bar{y}}) = g( \underset{1}{\bar{x}}, \underset{1}{h_1}(\bar{x}), \underset{0}{\bar{y}}, \underset{0}{h_0}(\bar{x}, \bar{y}))$ alors :
				
				\begin{itemize}[itemsep=-1mm]
					\item 	Soit $\text{tier}(f) = \text{tier}(g) = 1$, dans ce cas $f(\underset{1}{\bar{x}}) = g( \underset{1}{\bar{x}}, \underset{1}{h_1}(\bar{x}))$ (car on n'a pas d'argument redondant). Par hypothèse d'induction $\underset{1}{h_1}(\bar{x}) \equiv h_1(;\bar{x})$ et $g(\underset{1}{\bar{x}}, \underset{1}{h_1}(\bar{x})) \equiv g(; \bar{x}, h_1(;\bar{x})) = f(; \bar{x})$.
					
					\item 	Soit $\text{tier}(f) = \text{tier}(g) = 0$, dans ce cas par hypothèse d'induction, on a bien : $g( \bar{x}, h_1(\bar{x};) ; \bar{y}, h_0(\bar{x}; \bar{y})) = f(\bar{x} ; \bar{y})$.
				\end{itemize}
				
				Le cas de la récurrence ramifiée se résout de manière analogue.
			\end{proof}
			
	
			L'équivalence entre les deux se généralise sans problème aux algèbres de mots voire aux algèbres quelconques (bien que dans le cas d'algèbres quelconques, on ne sache pas s'il y a équivalence entre $P$ et $\text{BC}$ ou $\TRec{A}$).
			
			
	


	\pagebreak
	
	\section{Une histoire de RAMs}
	\label{sec:RAM_story}

	
		\subsection{La $\sigma$-RAM de Grandjean-Schwentick}
		\label{subsec:sigma_RAM}
		
		
		Soit $\sigma$ une signature fonctionnelle unaire ou binaire, typiquement $\sigma = \left\lbrace +, -, \times, \div 2\right\rbrace$. 
		
		
		\begin{definition}[$\sigma$-RAM \cite{GrandjeanSchwentick2002}] 
			\label{def:sigma_RAM}
			
			Une $\sigma$-RAM est un modèle de calcul composé de :

			\begin{itemize}[itemsep=-1mm]
				\item	Deux accumulateurs $A$, $B$ ;
				\item 	Un registre spécial $N$ ;
				\item 	Une infinité dénombrable de registres $\left( R_i\right)_{i \in \omega}$.
			\end{itemize}
			
			Les registres contiennent \emph{a priori} des valeurs entières.
			
			Un programme de $\sigma$-RAM est un ensemble fini d'instructions $\left( I(i) \right)_{i \in N}$ dont chacune est de l'une des formes suivantes :
			
			\begin{itemize}[itemsep=-1mm]
				\item 	$A := c$ pour n'importe quelle constante $c \in \naturels$
				\item 	$A := op(A)$ ou $op(A,B)$, où $op \in \sigma$
				\item 	$A := N$ 
				\item 	$N := A$
				\item 	$A := R_A$
				\item 	$B := A$ 
				\item 	$R_A := B$
				\item 	$\sRAMif{i}{j}$
				\item 	$\text{HALT}$
			\end{itemize}	
			
			
			\paragraph{Explications.} 
			Ces instructions sont assez claires. $R_A$ est le registre $R_j$ où $j$ est la valeur contenue dans l'accumulateur $A$. La commande $IF$ renvoie à l'instruction $i$ si $A = B$ et à $j$ sinon.
			Par défaut, tous les registres sont initialisés à $0$.
			
			Cette $\sigma$-RAM est déterministe. On pourrait la rendre non-déterministe en autorisant une commande $A := \text{CHOOSE}(A)$ ou une commande $\text{GOTO}\left( I(i_1), \dots, I(i_t)\right)$ qui permet d'effectuer plusieurs instructions en même temps. 
		\end{definition}
		
		
			\paragraph{Entrées et sorties.}
			Dans leur article \cite{GrandjeanSchwentick2002}, Grandjean et Schwentick indiquent que leur $\sigma$-RAM prend en entrée une structure $\left( \intint{1}{n},  f_1, \dots, f_k, C_1, \dots, C_l \right)$ où $f_1, \dots, f_k$ sont des fonctions unaires et $C_1, \dots, C_l$ sont des constantes ; la $\sigma$-RAM s'initialise de la façon suivante : 
			
			\begin{itemize}[itemsep=-1mm]
				\item 	$N := n$
				\item 	$R_{(i-1) \times n + j} := f_i(j)$ où $i \in \intint{1}{k}$ et $j \in \intint{1}{n}$
				\item 	$R_{k \times n + j} := C_i$ où $i \in \intint{1}{l}$
			\end{itemize}
			(La taille est stockée dans $N$ et les fonctions sont stockées dans l'ordre de numérotation).
			
			La sortie est une nouvelle structure $\left( \intint{1}{n'}, f'_1, \dots, f'_{k'}, C'_1, \dots, C'_{l'}\right)$ stockée de manière similaire dans la $\sigma$-RAM. 
		
		
		\begin{theorem}
			\label{thm:sRAMs_turing_complete}
			\emph{Une machine de Turing (binaire ?) simule une $\sigma$-RAM (pour quel $\sigma$ ?) en temps ??? et une $\sigma$-RAM simule une machine de Turing en temps polynomial.}
		\end{theorem}
		
		\nepasoublier{Il me faut une source pour la $\sigma$-RAM.}.
		
		
		
		
		\subsection{La $\bbA$-RAM de Leivant}
		\label{subsec:A_RAM_de_Leivant}
		
		Soit $\bbA$ une $\sigma$-algèbre. 
		
		\begin{definition}[$\mathbb{A}$-RAM \cite{Leivant1995}]
			\label{def:A_RAM}
			Une $\bbA$-RAM est un modèle de calcul comprenant :
			
			\begin{itemize}[itemsep=-1mm]
				\item 	Un ensemble fini d'états $S = \left\lbrace s_1, \dots, s_l \right\rbrace$, où $s_1$ est l'état initial et $s_l$ est l'état final ;
				\item 	Un ensemble fini de registres $\Pi = \left\lbrace \pi_1, \dots, \pi_m \right\rbrace$.
			\end{itemize}
			
			Les registres contiennent des termes de l'algèbre $\bbA$. Par défaut, on leur assigne une valeur $d$ parmi les constructeurs d'arité $0$ choisie à l'avance.
			
			Un programme de $\bbA$-RAM est un ensemble fini d'instructions dont chacune est de l'une des formes suivantes :
			
			\begin{itemize}[itemsep=-1mm]
				\item 	(const)			$s_a \pi_{j_1} \dots \pi_{j_{r_i}} C_i \pi_j s_b$
				\item	($p$-dest)		$s_a \pi_i \pi_j s_b$
				\item	(switch)		$s_a \pi_j s_{b_1} \dots s_{b_k}$
			\end{itemize}
			
			
			\paragraph{Explications.}
			Pour des raisons de lisibilité et de simplification d'écriture, on notera $*j$ le contenu du registre $\pi_j$. 
			
			La commande (const) $s_a \pi_{j_1} \dots \pi_{j_{r_i}} C_i \pi_j s_b$ peut se lire : si la $\bbA$-RAM est dans l'état $s_a$ alors $\pi_j := C_i\left( *j_1, \dots, *j_{r_i}\right)$ (on construit un nouveau terme $C_i\left( *j_1, \dots, *j_{r_i} \right)$ que l'on place dans $\pi_j$). Après avoir effectué l'instruction, la $\bbA$-RAM passe à l'état $s_b$.

			La commande ($p$-dest) $s_a \pi_i \pi_j s_b$ permet, si la $\bbA$-RAM est dans l'état $s_a$, de récupérer le $p$-ième argument du constructeur extérieur du terme $*i$ pour le stocker dans $\pi_j$. Si on détruit un constructeur d'arité $0$, alors on récupère la valeur par défaut. Après avoir effectué l'instruction, la $\bbA$-RAM passe à l'état $s_b$. Notons que le label ($p$-dest) est indispensable pour savoir quel sous-terme récupérer. 
			
			La commande (switch) $s_a \pi_j s_{b_1} \dots s_{b_k}$ lit $\pi_j$ et place la $\bbA$-RAM dans l'état $s_{b_i}$ si le constructeur extérieur de $*j$ est $C_i$. Bien sûr, tous les constructeurs $C_i$ doivent être représentés par un état $s_{b_i}$.
			
			Cette $\bbA$-RAM est déterministe lorsque, à chaque état $s_a$, correspond une unique commande, et non-déterministe sinon.
		\end{definition}
		
		
			\paragraph{Entrées et sorties.}
			Les entrées et les sorties sont des termes de $\bbA$. Si la $\bbA$-RAM prend $k$ entrées, alors ces entrées sont stockées dans les $k$ premiers registres de la machine. La sortie se trouve dans le dernier registre $\pi_m$. 
		
		
		\begin{theorem}
			\label{thm:ARAMs_turing_complete}
			Une $\mathbb{W}$-RAM simule une machine de Turing binaire en temps linéaire et une machine de Turing binaire simule une $\mathbb{W}$-RAM en temps polynomial.
		\end{theorem}
			
		La démonstration se trouve dans \cite{Leivant1995}.
		
		
		
		
		\subsection{Comparaison entre les deux RAM}
		\label{subsec:comparaison_RAMs}

			
			\subsubsection{$\bbA$-RAM dans $\sigma$-RAM}
			\label{subsubsec:sim_A_RAM_sigma_RAM}
	
				Le but de cette section est de simuler une $\bbA$-RAM dans une $\sigma$-RAM et inversement.
				
				\paragraph{Premières observations.}
				\label{par:premieres_observations}
				Premièrement, la $\sigma$-RAM calcule des entiers alors que la $\bbA$-RAM construit des termes. Cette remarque plutôt intuitive est pourtant la cause \emph{meta} des différences de puissance de ces machines. La $\sigma$-RAM se veut un modèle de calcul très proche de l'ordinateur réel (la mémoire réelle n'est certes pas infinie, mais suffisamment grande pour que ça ne soit pas un problème), alors que la $\bbA$-RAM se veut un modèle plus logique (construction de termes). De plus, la machine de Leivant est très frustre car il l'a construite pour qu'elle colle parfaitement à sa caractérisation de $DTIME_{\bbA}(n^k)$ (théorème \ref{thm:TRecA_equals_P_poly_fixe}).
				
				Deuxièmement, la mémoire de la $\sigma$-RAM est infinie et celle de la $\bbA$-RAM est finie et ne doit pas dépendre de l'entrée.
				Troisièmement, la $\sigma$-RAM dispose d'un test d'égalité gratuit, ce qui n'est pas le cas de la $\bbA$-RAM.
				Enfin, la $\bbA$-RAM a une commande de destruction de terme qui n'a pas réellement d'équivalent dans la $\sigma$-RAM. 
				
				Afin de contourner le premier problème, on va étendre la définition de la $\sigma$-RAM pour qu'elle construise elle aussi des termes. Quant aux autres problèmes, il va falloir ruser. Pour la mémoire, on va utiliser une astuce et distinguer quelques registres qui contiendront des termes très grands - mais qui ralentiront l'accès à la mémoire. Le test d'égalité sera simulé lourdement par la $\bbA$-RAM et on rajoutera une commande en plus à la $\sigma$-RAM pour copier la destruction de terme. 
				
				\espace
				
				Soit $\sigma = \left\lbrace C_1, \dots, C_k \right\rbrace$ une signature de constructeurs. On note $r = \maxlist{r_i}{i \in \intint{1}{k}}$. On suppose que $r > 0$.
				
				Notons $\bbA$ la $\sigma$-algèbre contenant ces termes.
				
				\begin{definition}[$\sigma$-RAM constructrice]
					\label{def:sigma_RAM_constructrice}
					Une $\sigma$-RAM constructrice est un modèle de calcul composé de :
					
					\begin{itemize}[itemsep=-1mm]
						\item	Des accumulateurs $\left(A_i\right)_{i\in \intint{1}{r}}$ (si $r$ = 1, on suppose qu'on a au moins deux accumulateurs) ;
						\item 	Un registre spécial $N$ ;
						\item 	Une infinité dénombrable de registres $\left( R_i\right)_{i \in \omega}$.
					\end{itemize}
				
					
					Les instructions sont similaires à celles de la $\sigma$-RAM classique :
					
					\begin{itemize}[itemsep=-1mm]
						\item 	$A_1 := c$ pour n'importe quelle constante $c \in \bbA$
						\item 	$A_1 := C_i(A_1, \dots, A_{r_i})$ où $C_i \in \sigma$
						\item 	$A_1 := N$
						\item 	$A_1 := \text{dest}_p(A_1)$ où $p \in \intint{1}{r}$
						\item 	$N := A_1$
						\item 	$A_1 := R_{A_1}$
						\item 	$A_i := A_1$ où $i \in \intint{2}{\max\left( 2, r \right)}$
						\item 	$R_{A_1} := A_i$ où $i \in \intint{2}{\max\left( 2, r \right)}$
						\item 	$\sRAMifc{i}{j}$
						\item 	$\text{HALT}$
					\end{itemize}
					
					On garde les commandes classiques et on rajoute une commande de destruction $A_1 := \text{dest}_p(A_1)$ qui a exactement le même principe que \hyperref[def:A_RAM]{la commande analogue dans la $\bbA$-RAM}.
				\end{definition}
				
				Pour donner du sens à $R_{A_1}$, deux choix s'offrent à nous. Soit on suppose que les registres sont numérotés par des entiers naturels et, puisque $\bbA$ est dénombrable, on a une bijection entre $\bbA$ et $\naturels$. On suppose alors que $R_{A_1}$ est le registre dont l'indice est l'image du terme contenu dans $A_1$ par la bijection. Sinon, on peut considérer que les registres sont numérotés directement par des termes.
				
				Dans la suite, on va se placer dans le cas où l'on a une bijection $f : \naturels \to \bbA$.
				De plus, par abus de langage, on parlera de $\sigma$-RAM sans préciser si elle est constructrice ou non (elle le sera par défaut). 

	
				
				\paragraph{Simulation.}
				\label{par:sim_A_RAM_sigma_RAM}
				On considère la signature $\sigma = \{C_1, \dots, C_k\}$ et la $\sigma$-algèbre $\bbA$.
				
				\begin{lemma}
					\label{lem:sim_A_RAM_sigma_RAM}
					Une $\bbA$-RAM peut être simulée en temps linéaire par une $\sigma$-RAM.
				\end{lemma}
				
				\begin{proof}
					Les registres de la $\bbA$-RAM seront simplement simulés par les registres de la $\sigma$-RAM. 
					
					Si la $\bbA$-RAM est déterministe, alors ses états n'ont qu'un seul état suivant. Dans ce cas, le passage d'un état à un autre est simulé dans la $\sigma$-RAM comme simplement le passage d'un ensemble d'instructions à un autre. Si la $\bbA$-RAM est non-déterministe, alors on peut passer à plusieurs états en même temps. Pour simuler cela, on autorise une commande $\text{GOTO}(I(j_1), \dots, I(j_t))$ qui permet d'aller aux instructions correspondantes. 
					
					Il suffit de traduire les instructions de la $\bbA$-RAM en suite d'instructions de la $\sigma$-RAM.
					
					\subparagraph{(const)}
					$s_a \pi_{j_1} \dots \pi_{j_{r_i}} C_i \pi_j s_b$
					
					
					
					
					\begin{algorithm}[H]
						\caption{Simulation de la commande (const)}
						
						\KwIn{Registres sources $j_1, \dots, j_{r_i}$, registre d'arrivée $j$, constructeur $C_i$}
						
						\tcp{Dans la boucle, on récupère les arguments voulus :}
						
						\For{$t$ from $r_i$ to $1$}{
							$A_1 := f(j_t)$\;
							$A_1 := R_{A_1}$\;
							$A_t := A_1$\;
							}
							
						\tcp{On construit le terme :}
						
						$A_1 := C_i (A_1, \dots, A_{r_i})$\;
						
						\tcp{On stocke le résultat dans $R_{f(j)}$ :}
						
						$A_2 := A_1$\;
						$A_1 := f(j)$\;
						$R_{A_1} := A_2$\;
					\end{algorithm}
					
					\espace
					
					Cette simulation se fait en $3r_i + 4$ étapes de calcul. La boucle \emph{for} ici écrite n'est pas une réelle boucle \emph{for}. Il s'agit d'une manière lisible d'écrire des instructions, dont le nombre ne dépend que de $r_i$.

					
					\subparagraph{($p$-dest)}
					$s_a \pi_i \pi_j s_b$
					
					\begin{algorithm}[H]
						\caption{Simulation de la commande ($p$-dest)}
						
						\KwIn{Registres $i,j$}
						
						\tcp{On récupère le contenu de $R_{f(i)}$ :}
						$A_1 := f(i)$\;
						$A_1 := R_{A_1}$\;
						
						\tcp{On récupère son $p$-ième sous-terme (on effectue l'opération de destruction) : }
						$A_1 := \text{dest}_p(A_1)$\;
						
						\tcp{On déplace le résultat dans $R_{f(j)}$ : }
						$A_2 := A_1$\;
						$A_1 := f(j)$\;
						$R_{A_1} := A_2$\;
					\end{algorithm}
					
					\espace
					
					Cette simulation se fait en $6$ étapes de calcul.
					
					\subparagraph{(switch)}
					$s_a \pi_j s_{b_1} \dots s_{b_k}$
					
					Rappelons-nous que les états $s_{b_i}$, dans une $\bbA$-RAM, correspondent à des numéros d'instruction $j_i$ dans la $\sigma$-RAM. 
					
					\begin{algorithm}[H]
						
						\KwIn{Registre $j$, instructions $I\left( j_1 \right), \dots, I\left( j_k \right)$}
						
						\tcp{On détruit entièrement le terme  et on récupère chacun des arguments du constructeur extérieur de $R_{f(j)}$. Si l'arité du constructeur est strictement inférieure à $p$, on assigne une valeur par défaut au registre.}
						
						\For{$p$ from $r$ to $1$}{
							$A_1 := f(j)$\;
							$A_1 := R_{A_1}$\;
							$A_p := \text{dest}_p(A_1)$\;
							}
						
						
						\For{$i$ from $1$ to $k$}{
							
							\tcp{On construit un terme :}
							$A_1 := C_i(A_1, \dots, A_{r_i})$\;
							
							\tcp{On le met de côté, à disposition, quitte à écraser le contenu de $A_2$ :}
							$A_2 := A_1$\;
							
							\tcp{On récupère le terme qu'on voulait analyser :}
							$A_1 := f(j)$\;
							$A_1 := R_{A_1}$\;
							
							\eIf{$A_1 = A_2$}{
								\tcp{Alors on a reconstruit le même terme ; ça veut dire qu'on est au bon $i$. Dans ce cas, on va à l'instruction $j_i$ :}
								
								%$\sRAMifc{j_i}{j_i}$\;  
								
								%\tcp{Astuce pour avoir un GOTO}
								
								Aller à l'instruction $I\left(j_i\right)$\;
								
								}
								% Else 
								{
									\tcp{Sinon, on s'est trompé. Dans ce cas, on récupère l'argument qu'on venait d'effacer dans $A_2$ :}
									
									$A_1 := \text{dest}_2(A_1)$\;
									$A_2 := A_1$\;
									
									\tcp{On récupère aussi le premier sous-terme, pour pouvoir faire une nouvelle construction par la suite :}
									
									$A_1 := f(j)$\;
									$A_1 := R_{A_1}$\;
									
									\tcp{Et on continue la boucle.}
								}
							}
						\tcp{On construit un nouveau terme en regardant chaque constructeur et on vérifie s'il est égal au terme de $R_{f(j)}$}
					
						\caption{Simulation de la commande (switch)}
					\end{algorithm}
					
					\espace 
					
					La simulation se fait en $\leq 3r + 9k$ étapes. Les boucles \emph{For} sont des simplifications d'écriture.
				
					\paragraph{Bilan.}
					Chaque instruction de la $\bbA$-RAM peut être simulée en temps constant par une $\sigma$-RAM.
				\end{proof}
	
	
				\subsubsection{$\sigma$-RAM dans $\bbA$-RAM}
				\label{subsubsec:sim_sigma_RAM_A_RAM}
				
				
				\begin{lemma}
					\label{lem:sim_sigma_RAM_A_RAM}
					Une $\sigma$-RAM fonctionnant en temps polynomial peut être simulée en temps polynomial par une $\bbA$-RAM.
				\end{lemma}
	
				\begin{proof}
					Ici, nous allons surtout présenter les algorithmes. La programmation en $\bbA$-RAM est disponible en \hyperref[sec:annexes_programmes]{annexes}.
					
					Avant d'en venir à la simulation proprement dite, on va d'abord décrire quelques fonctions.
			
					
					\paragraph{Copie.}
					
					La $\bbA$-RAM permet une copie indépendante de la longueur du terme. 
					
					\espace 
					
					\begin{algorithm}[H]
						\label{algo:A_RAM_fn_COPY}
						\KwIn{Registres $\alpha, \beta, \pi_1, \dots, \pi_r$}
						\tcp{Détruit le terme contenu dans $\alpha$, stocke ses composantes dans chaque $\pi_p$, puis reconstruit le terme dans $\beta$.}
						
						\For{$p$ from $1$ to $r$}{
							Récupérer le $p$-ième sous-terme de $\alpha$ et le stocker dans $\pi_p$ \;
							}
							
						Selon le constructeur extérieur de $\alpha$, utiliser le même constructeur pour construire dans $\beta$ l'exact même terme, utilisant les mêmes sous-termes stockés dans les $\pi_1, \dots, \pi_r$.
						
						\caption{La fonction $s_{a_1}\text{COPY}(\alpha, \beta, \bar{\pi}) s_b$. Programme \hyperref[prog:A_RAM_fn_COPY]{en annexe}.}
					\end{algorithm}
						
					\espace
					
					La copie se fait en temps constant ($r+2$).
					
	
					\paragraph{Egalité.}
					Pour gérer le premier problème, on va écrire un test d'égalité. Puisqu'on ne peut comparer que les constructeurs extérieurs des termes, on va effectuer ces comparaisons, puis déconstruire le terme et recommencer les comparaisons. Puisque le nombre de sous-termes peut dépasser la capacité (finie) d'une $\bbA$-RAM, on va utiliser un fragment de l'astuce ci-dessous concernant la mémoire : à chaque décomposition de terme, on stockera les sous-termes dans une mémoire en forme de liste. Ce moyen est explicité juste \hyperref[par:A_RAM_memoire]{en-dessous}.
	
					
					\espace 
					
					\begin{algorithm}[H]
						\label{algo:A_RAM_fn_IF}
						\KwIn{$\alpha, \beta, s_1, s_0, \pi_1, \pi_2, \pi'_1, \pi'_2$}
						\tcc{$\alpha, \beta$ : les registres contenant les termes à tester.\\
							$s_1, s_0$ : place la machine dans l'état $s_1$ si $\alpha = \beta$, $s_0$ sinon. \\
							$\pi_1, \pi_2$ : registres de travail ; contiendront respectivement la liste des sous-termes de $\alpha$ et $\beta$ qui n'ont pas encore été comparés. \\
							$\pi'_1, \pi'_2$ : registres de travail ; contiendront les sous-termes courants. \\ \\
							Vérifie si $\alpha = \beta$ en faisant une analyse inductive sur la construction des termes qu'ils contiennent.}
						
						\espace
						\espace
						
						Copier $\alpha$ dans $\pi'_1$ \;
						Copier $\beta$ dans $\pi'_2$ \;
						
						\tcp{C'est une boucle $\text{do} \dots \text{while}$ à la C++ ; on doit passer au moins une fois dedans.}
						
						\While{$\pi_1$ et $\pi_2$ sont non vides}{
							
							\eIf{$\pi'_1$ et $\pi'_2$ ont les mêmes constructeurs extérieurs}{
								
								\If{$\pi'_1$ et $\pi'_2$ ont des sous-termes}{
									Empiler les sous-termes de $\pi'_1$ dans $\pi_1$ \;
									Empiler les sous-termes de $\pi'_2$ dans $\pi_2$ \;
									}
								
								Récupérer le premier élément de $\pi_1$ et le stocker dans $\pi'_1$ \;
								Récupérer le premier élément de $\pi_2$ et le stocker dans $\pi'_2$ \;
								Dépiler $\pi_1$ \;
								Dépiler $\pi_2$ \;
								}{
									\textbf{Aller à l'état $s_1$} \;
								}
							}
						\textbf{Aller à l'état $s_0$} \;

						
						\caption{Fonction $\text{IF}(\alpha, \beta, s_1, s_0, \pi_1, \pi_2, \pi'_1, \pi'_2)$. Programme \hyperref[prog:A_RAM_fn_IF]{en annexe}.}
					\end{algorithm}
					
					\espace
					
					Cette fonction fait le test d'égalité en temps $\grozo{\min\left(\abs{\alpha}, \left| \beta \right|\right)}$. Ce n'est donc pas un test gratuit. 
					
					
					\paragraph{Mémoire.}
					\label{par:A_RAM_memoire}
					Pour le second problème, on va supposer que la $\bbA$-RAM a le droit d'utiliser deux constructeurs supplémentaires $\text{MEM}(-,-,-)$ et $\varepsilon$. La mémoire de la $\sigma$-RAM sera simulée par un terme de la forme : 
					
					$\text{MEM}(f(i_1), R_{f(i_1)}, \text{MEM}( \dots, \text{MEM}(f(i_n), R_{f(i_n)}, \varepsilon) \dots ) )$
					
					Le premier argument de $\text{MEM}$ est l'indice du registre, le deuxième est son contenu, et le troisième la suite de la mémoire. Notons qu'on ne suppose pas que les indices sont ordonnés, car ils ne pourront pas l'être. 
					
					Le but est de pouvoir reproduire la mémoire de la $\sigma$-RAM en autorisant un (ou plusieurs) terme(s) de longueur non bornée. 
					
					Pour utiliser cette mémoire, on va distinguer cinq registres : $\mu$ et $\left( \mu_i \right)_{i \in 4}$.
					
					Le registre $\mu_1$ contiendra l'indice courant de la mémoire, $\mu_2$ contiendra la valeur du registre associé. $\mu_3$ contiendra la mémoire \emph{suivante} et $\mu_4$ la mémoire précédente. Le registre $\mu$ est copiée dans $\mu_3$ à l'initialisation de certaines fonctions, puis $\mu_3$ est déroulée, en stockant le contenu passé dans $\mu_4$. 
					
					On définit des fonctions associées qui permettront de mieux comprendre comment on se sert de cette mémoire. 
					
					\espace
					
					\begin{algorithm}[H]
						\label{algo:A_RAM_fn_INSERT}
						
						\KwIn{Registres $\mu, \mu_1, \mu_2, \mu_3, \mu_4, \alpha, \beta, \pi_1, \pi_2, \pi'_1, \pi'_2$}
						
						\tcc{
							$\mu, (\mu_i)_{i\in 4}$ sont tels que décrits plus haut.\\
							$\alpha$ est l'indice auquel on veut insérer. \\
							$\beta$ est la valeur qu'on veut insérer à l'indice $\alpha$. \\
							$\pi_1, \pi_2, \pi'_1, \pi'_2$ sont les registres de travail nécessaires au test d'égalité.
							}
						
						\espace
						
						\tcp{Initialisation de la mémoire}
						
						Copier $\mu$ dans $\mu_3$ \;
						Vider $\mu_4$ \;
						Stocker le premier indice et la première valeur de $\mu$ dans $\mu_1$ et $\mu_2$ \;
						
						\espace
						
						\tcp{Première boucle : on avance dans la mémoire en vérifiant à chaque fois si on est au bon indice.}
						
						\While{$\mu_3$ est non-vide}{
							Empiler $\left(\mu_1, \mu_2\right)$ dans $\mu_4$ \;
							Stocker le premier indice de $\mu_3$ dans $\mu_1$ \;
							Stocker la première valeur de $\mu_3$ dans $\mu_2$ \;
							Dépiler $\mu_3$ \;
							
							\If{$\alpha = \mu_1$}{
								Sortir de la boucle While \;
								}
							}
							
							
						Empiler $\left( \mu_1, \beta \right)$ dans $\mu_3$ \;
						
						\espace
						
						\tcp{Deuxième boucle : étape inverse : on récupère tout ce qu'on a visité précédemment.}
						
						\While{$\mu_4$ est non-vide}{
							Empiler $\left(\mu_1, \mu_2\right)$ dans $\mu_3$ \;
							Stocker le premier indice de $\mu_4$ dans $\mu_1$ \;
							Stocker la première valeur de $\mu_4$ dans $\mu_2$ \;
							Dépiler $\mu_4$ \;
						}
						
						Copier $\mu_3$ dans $\mu$ \;
						
						\caption{Fonction $\text{INSERT}\left( \mu, \mu_1, \mu_2, \mu_3, \mu_4, \alpha, \beta, \pi_1, \pi_2, \pi'_1, \pi'_2\right)$. Programme \hyperref[prog:A_RAM_fn_INSERT]{ici}. }
					\end{algorithm}
					
					\espace 
					
					La fonction $\text{INSERT}$ fonctionne en temps $\leqslant \grozo{\abs{\mu} \times \max\left( \abs{\mu} , \abs{\alpha} \right) }$.
					
					\espace
					
					\begin{algorithm}[H]
						\label{algo:A_RAM_fn_ACCESS}
						\KwIn{$\mu, \mu_1, \mu_2, \mu_3, \mu_4, \alpha, \beta, \pi_1, \pi_2, \pi'_1, \pi'_2$}
						
						\tcc{
							$\mu, (\mu_i)_{i\in 4}$ sont tels que décrits plus haut.\\
							$\alpha$ est l'indice auquel on veut insérer. \\
							$\beta$ est la valeur qu'on veut insérer à l'indice $\alpha$. \\
							$\pi_1, \pi_2, \pi'_1, \pi'_2$ sont les registres de travail du test d'égalité.
						}
						
						\tcp{Initialisation de la mémoire}
						
						Copier $\mu$ dans $\mu_3$ \;
						Vider $\mu_4$ \;
						Stocker le premier indice et la première valeur de $\mu$ dans $\mu_1$ et $\mu_2$ \;
						
						\espace
						
						\tcp{Boucle : avancer dans la mémoire jusqu'à trouver le bon indice.}
						
						\While{$\mu_3$ est non-vide}{
							Stocker le premier indice de $\mu_3$ dans $\mu_1$ \;
							Stocker la première valeur de $\mu_3$ dans $\mu_2$ \;
							Dépiler $\mu_3$ \;
							
							\If{$\alpha = \mu_1$}{
								Sortir de la boucle While \;
							}
						}
						
						
						Copier $\mu_2$ dans $\beta$ \;
						
						\caption{Fonction $\text{ACCESS}\left( \mu, \mu_1, \mu_2, \mu_3, \mu_4, \alpha, \beta, \pi_1, \pi_2, \pi'_1, \pi'_2\right)$. Programme \hyperref[prog:A_RAM_fn_ACCESS]{ici}. }
					\end{algorithm}
					
					\espace

					La fonction $\text{ACCESS}$ fonctionne en temps $\leqslant \grozo{\abs{\mu} \times \max\left( \abs{\alpha} , \left| \text{longueur des adresses déjà employées} \right| \right) }$.
					
					\paragraph{Simulation.}
					\label{par:sim_sigma_RAM_A_RAM}
					Pour $\bbA$ engendrée par $k$ constructeurs $\sigma = \left\lbrace C_1, \dots, C_k\right\rbrace$ d'arité maximale $r$, la $\sigma$-RAM est constituée de $r$ accumulateurs $A_1, \dots, A_r$ (si $r = 1$, on suppose qu'il y en a au moins $2$), un registre spécial $N$ et une infinité de registres $(R_i)_{i \in \omega}$. Pour simuler cette $\sigma$-RAM, on va utiliser une $\bbA$-RAM contenant un registre spécial pour chaque accumulateur $(\alpha_i)_{i \in k}$, un registre $\nu$, cinq registres spéciaux dédiés à la gestion de la mémoire $\mu, (\mu_i)_{i \in 4}$, $r+4$ registres de travail $\overline{\pi''}, \pi_1, \pi_2, \pi'_1, \pi'_2$.
					
					Les états de la $\bbA$-RAM seront simplement calqués sur les numéros des instructions du programme de la $\sigma$-RAM. Si une instruction de $\sigma$-RAM se simule en un programme de $\bbA$-RAM, alors l'état initial de cette simulation est l'état correspondant au numéro de l'instruction, et l'état final correspond au numéro de l'instruction suivante. Les états intermédiaires dans les fonctions sont des états qui n'apparaissent nulle part ailleurs que dans la fonction associée, afin d'éviter les conflits. 
						
						\subparagraph{Entrées/sorties.}
						Dans une $\sigma$-RAM, les entrées sont stockées dans des registres au choix. Il suffit de reproduire cette initialisation en remplissant les registres équivalents dans la $\bbA$-RAM. Si $A_i, N$ sont initialisés, alors initialiser $\alpha_i, \nu$ de la même façon. Si des registres $R_i$ sont initialisés, alors on initialise $\mu$ avec un terme mémoire : 
						
						$\text{MEM}\left( f(0), R_0, \text{MEM}\left( f(1), R_1, \dots \right) \dots \right)$.
						
						Dans la suite, $(a)$ sera le numéro de l'instruction étudiée. 
						
						\subparagraph{Assignation de terme.}
						$(a) \:\: A := c$ où $c \in \bbA$ est un terme indépendant du calcul, se simule en temps constant en reconstruisant \emph{manuellement} le terme $c$ dans la $\bbA$-RAM. 
						
						\subparagraph{Instructions de copie.}
						$(a) \:\: A_1 := N$ se simule en temps constant par : (fn) $s_a \text{COPY}(\nu, \alpha_1, \bar{\pi}) s_{a+1}$.
						 
						$(a) \:\: N := A_1$ se simule en temps constant par : (fn) $s_a \text{COPY}(\alpha_1, \nu, \bar{\pi}) s_{a+1}$.
						
						$(a) \:\: A_i := A_1$ se simule en temps constant par : (fn) $s_a \text{COPY}(\alpha_1, \alpha_i, \bar{\pi}) s_{a+1}$.
					
						\subparagraph{Construction.}
						$(a) \:\: A_1 := C_i(A_1, \dots, A_{r_i})$ se simule par l'instruction : (const) $s_a \alpha_1 \dots \alpha_{r_i} C_i \alpha_1 s_{a+1}$.
						
						\subparagraph{Destruction.}
						$(a) \:\: A_1 := \text{dest}_p(A_1)$ se simule par l'instruction : ($p$-dest) $s_a \alpha_1 \alpha_1 s_{a+1}$.
						
						\subparagraph{HALT.}
						$(a) \:\: \text{HALT}$ ne se simule pas vraiment ; il s'agit plutôt de faire coïncider l'état final de la $\bbA$-RAM avec tous les états correspondant à une instruction $\text{HALT}$. 
						
						\subparagraph{Accès mémoire.}
						$(a) \:\: A_1 := R_{A_1}$ se simule par : (fn) $s_a \text{ACCESS}\left( \mu, \mu_1, \mu_2, \mu_3, \mu_4, \alpha_1, \alpha_1, \pi_1, \pi_2, \pi'_1, \pi'_2\right) s_{a+1}$ en temps $\grozo{\abs{\mu} \times \abs{\alpha}}$.
						
						\subparagraph{Insertion mémoire.}
						$(a) \:\: R_{A_1} := A_i$ se simule par : (fn) $s_a \text{INSERT}\left( \mu, \mu_1, \mu_2, \mu_3, \mu_4, \alpha_1, \alpha_i, \pi_1, \pi_2, \pi'_1, \pi'_2\right) s_{a+1}$ en temps $\grozo{\max\left( \abs{\alpha}, \abs{\mu} \right)\times \abs{\mu}}$. 
						
						\subparagraph{Test d'égalité.}
						$(a) \:\: \sRAMifc{i}{j}$ se simule par : (fn) $s_a \text{IF}\left( \alpha_1, \alpha_2, s_i, s_j, \pi_1, \pi_2, \pi'_1, \pi'_2 \right) s_{a+1}$ en temps $\grozo{\min\left( \left| \alpha_2\right|, \left| \alpha_2 \right| \right)}$
						
						
					\paragraph{Bilan.}
					La $\bbA$-RAM simule lourdement trois des opérations de base de la $\sigma$-RAM. Les deux machines coïncident sur les \emph{grosses} classes de complexité ($P$, $NP$, $EXP$...) mais pas sur les classes plus fines ($\text{DTIME}(n^k)$ pour un $k$ fixé).
				\end{proof}
				
				
				
				
			\subsubsection{Cas particulier : entiers unaires}
			\label{subsubsec:sim_succ_RAM_N_RAM}
							
				La $\sigma$-RAM permet l'accès à n'importe quel endroit de sa mémoire avec le registre $A$. Dans le cas général, la $\bbA$-RAM doit utiliser des astuces pour reproduire cet accès du mieux possible. 
				
				
				On peut obtenir une légèrement meilleure simulation de la $\sigma$-RAM par la $\bbA$-RAM dans le cas d'une signature $\sigma = \left\lbrace 0, s(-)\right\rbrace$. On note $\naturels$ l'algèbre engendrée par cette signature $\sigma$.
				
				De manière générale, les programmes sont plus simples à écrire car il n'y a qu'un constructeur, et avec une astuce de gestion de mémoire, on arrive à une machine un peu plus rapide. L'astuce consiste à synchroniser la valeur du registre $\alpha$ avec l'indice en mémoire. Si on augmente $\alpha$ de 1, alors on avance d'un pas dans la mémoire. 
				
				Cette optimisation repose sur une contrainte : on impose au registre $\alpha$ de la $\bbA$-RAM de toujours représenter l'indice de la mémoire, puisque c'est le cas dans la $\sigma$-RAM. Il faut donc que, à chaque fois que l'on modifie "brutalement" $A$ dans la $\sigma$-RAM, par exemple avec l'opération $A :=0$, on se déplace dans la mémoire. Quand on effectue l'opération $A:=s(A)$ dans la $\sigma$-RAM, on se déplace d'un pas dans la mémoire de la $\bbA$-RAM. 
				
				Voici un petit bilan des gains et pertes :
				\begin{itemize}[itemsep=-1mm]
					\item 	L'opération $A:=0$ se simule en temps $\grozo{\abs{\alpha}}$ au lieu de $\grozo{1}$ ;
					\item 	L'opération $A:=N$ se simule en temps $\grozo{\max\left( \abs{\alpha}, \abs{\nu} \right)}$ au lieu de $\grozo{1}$ ;
					\item 	L'opération $A:=R_A$ (accès mémoire) se simule en temps $\grozo{\max\left( \abs{\alpha}, \abs{\mu_2} \right)}$ au lieu de $\grozo{\abs{\mu} \times \abs{\alpha}}$ (on rappelle que $\mu_2$ est la valeur de la case mémoire courante, et $\mu$ est le registre contenant toute la mémoire) ;
					\item 	L'opération $R_A:=B$ (insertion mémoire) se simule en temps  $\grozo{1}$ au lieu de $\grozo{\max\left( \abs{\alpha}, \abs{\mu} \right)\times \abs{\mu}}$
					\item 	L'opération $\sRAMifc{i}{j}$ (test d'égalité) se simule en temps $\grozo{\min\left( \abs{\alpha} , \abs{\beta} \right)}$, comme avant.
					\item 	Le reste des opérations se fait en temps constant.
				\end{itemize}
				
				Le principal gain est pour l'insertion en mémoire. On gagne aussi à l'opération d'accès mémoire, bien que le gain, intuitif, ne soit pas systématique. 
	
	
			\subsubsection{Une tentative d'amélioration}
			\label{subsubsec:sim_amelioration}
				
				Enfin, on peut penser à donner un test d'égalité gratuit à la $\bbA$-RAM. Il accélère la simulation des trois opérations de base de la $\sigma$-RAM, mais il reste un coût : 
				
				\begin{itemize}[itemsep=-1mm]
					\item 	$A_1 := R_{A_1}$ se simule à présent en temps $\grozo{\abs{\mu}}$ ;
					\item 	$R_{A_1} := A_i$ se simule à présent en temps $\grozo{\abs{\mu}}$ ;
					\item 	$\sRAMifc{i}{j}$ se simule à présent en temps $\grozo{1}$ ;
					\item 	Les autres instructions ne sont pas affectées.
				\end{itemize}
				
				De plus, le test d'égalité gratuit de la $\bb{N}$-RAM ne renforce que la simulation du test d'égalité de la $\{0,s(-)\}$-RAM. Cette optimisation ne souffrait pas de l'absence d'un test d'égalité gratuit. 
				
				La $\bbA$-RAM garde encore une fois un lourd point faible : la gestion de sa mémoire.
				
				Ici, nous avons utilisé une liste, mais dans le cas d'une algèbre de mots, on pourrait utiliser une mémoire avec embranchements (un terme $\text{MEM}\left( -, \dots, -\right)$, où chaque emplacement de la mémoire correspond à un constructeur). L'adresse est alors un mot et se traduit comme un ensemble de destructions successives du terme de mémoire, en prenant garde à récupérer le sous-terme correspondant au constructeur détruit.				

			\subsubsection{Problème majeur}

				La simulation présentée \hyperref[par:sim_sigma_RAM_A_RAM]{ici} de la $\sigma$-RAM par la $\bbA$-RAM n'est pas satisfaisante, car la technique utilisée permet d'avoir la mémoire dans un seul terme, donc de la copier et de la déplacer d'un bloc en une opération, ce qui est beaucoup trop puissant. 
				
				De plus, si le test d'égalité est rendu gratuit, on peut faire un test d'égalité entre deux termes de mémoire, ce qui n'est pas concevable.






%	\section{Vers une caractérisation du temps polynomial sur $\sigma$-RAM}
%		\label{sec:carac_poly_sigma_RAM}
%		
%		\subsection{Caractérisation du temps linéaire}
%			\label{subsec:carac_lineaire}
%			\label{subsec:resume_Grandjean_Schwentick}
%			
%		\begin{definition}[LSRS]
%			
%		\end{definition}
			
			
	\include{BrouillonGrandjeanSchwentick}
			

	\include{annexes}
			
	\bibliographystyle{plain}
	\bibliography{biblio}
			
\end{document}






















